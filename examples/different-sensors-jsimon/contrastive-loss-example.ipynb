{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch_utils as tu\n",
    "import utils as ut"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "timesteps_per_example_in_100Hz = 200\n",
    "num_examples = batch_size * 20\n",
    "\n",
    "sensor1 = ut.Sensor(40, 0.0, 0.2)\n",
    "sensor2 = ut.Sensor(80, 0.1, 0.1)\n",
    "sensor3 = ut.Sensor(80, 0.0, 0.3)\n",
    "sensor4 = ut.Sensor(20, 0.0, 0.1)\n",
    "sensors = [sensor1, sensor2, sensor3, sensor4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_options = [\n",
    "    transforms.Compose([tu.AblateBlock(5,30), tu.ToTensor()]),\n",
    "    transforms.Compose([tu.AddNoise((-0.1, 0.1), (0.0, 0.3)), tu.ToTensor()]),\n",
    "    transforms.Compose([tu.RandomDownsample(), tu.ToTensor()])\n",
    "]\n",
    "trsfm = transforms.RandomChoice(transform_options)\n",
    "\n",
    "dataset = tu.BadSensorsDataset(sensors,200, 20, jiggle_offsets=20, transform=trsfm, return_two_transforms=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = tu.BadSensorsDataset(sensors,timesteps_per_example_in_100Hz,\n",
    "                               num_examples, jiggle_offsets=None)\n",
    "\n",
    "# if everything worked right we now have 4 * 20 samples a 200 timepoints in 100Hz resolution\n",
    "assert len(dataset) == num_examples\n",
    "assert len(dataset[0]) == timesteps_per_example_in_100Hz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_size = 0.2\n",
    "test_size = 0.1\n",
    "num_workers = 2\n",
    "\n",
    "num_train = len(dataset)\n",
    "indices = list(range(num_train))\n",
    "train_idx, valid_idx, test_idx = ut.random_splits(indices, test_size, valid_size)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampeler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "    sampler=test_sampeler, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(n_epochs, model, projection, optimizer, train_loader, valid_loader):\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for i_batch, (sk1, sk2) in enumerate(train_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                sk1, sk2 = sk1.cuda(), sk2.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output, _ = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output, _ = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "\n",
    "        # print training/validation statistics\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, train_loss, valid_loss))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_mnist.pt')\n",
    "            valid_loss_min = valid_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}