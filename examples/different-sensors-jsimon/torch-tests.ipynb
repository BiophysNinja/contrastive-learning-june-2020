{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Torch Tests\n",
    "This notebook is for tests of Data Loaders and Transformations of PyTorch\n",
    "before we start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "import torch_utils as tu\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data with only two columns is assumed to have no missing value field, just return the whole index\n",
      "data with only two columns is assumed to have no missing value field, just return the whole index\n",
      "data with only two columns is assumed to have no missing value field, just return the whole index\n",
      "data with only two columns is assumed to have no missing value field, just return the whole index\n"
     ]
    }
   ],
   "source": [
    "sensor1 = ut.Sensor(40, 0.0, 0.2)\n",
    "sensor2 = ut.Sensor(80, 0.1, 0.1)\n",
    "sensor3 = ut.Sensor(80, 0.0, 0.3)\n",
    "sensor4 = ut.Sensor(20, 0.0, 0.1)\n",
    "sensors = [sensor1, sensor2, sensor3, sensor4]\n",
    "dataset = tu.BadSensorsDataset(sensors,200, 20, jiggle_offsets=None)\n",
    "\n",
    "# if everything worked right we now have 4 * 20 samples a 200 timepoints in 100Hz resolution\n",
    "assert len(dataset) == 4 * 20\n",
    "assert len(dataset[0]) == 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# let's see if iteration works correctly:\n",
    "\n",
    "last_samle = dataset[0]\n",
    "for i in range(1, 4 * 20):\n",
    "    sample = dataset[i]\n",
    "    # now we assume each sample to be quite different so:\n",
    "    diff = np.abs(last_samle - sample).sum()\n",
    "    if diff < 0.01:\n",
    "        print(\"unrealistic small change among different samples at \", i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data with only two columns is assumed to have no missing value field, just return the whole index\n",
      "data with only two columns is assumed to have no missing value field, just return the whole index\n",
      "data with only two columns is assumed to have no missing value field, just return the whole index\n",
      "data with only two columns is assumed to have no missing value field, just return the whole index\n",
      "0 2 10 torch.Size([200, 3])\n",
      "1 2 10 torch.Size([200, 3])\n",
      "2 2 10 torch.Size([200, 3])\n",
      "3 2 10 torch.Size([200, 3])\n",
      "4 2 10 torch.Size([200, 3])\n",
      "5 2 10 torch.Size([200, 3])\n",
      "6 2 10 torch.Size([200, 3])\n",
      "7 2 10 torch.Size([200, 3])\n"
     ]
    }
   ],
   "source": [
    "# we have a special case for transforms for contrastive learning:\n",
    "# we want to apply different transforms on the same section to make it invariant\n",
    "# for it\n",
    "\n",
    "transform_options = [\n",
    "    transforms.Compose([tu.AblateBlock(5,30), tu.ToTensor()]),\n",
    "    transforms.Compose([tu.AddNoise((-0.1, 0.1), (0.0, 0.3)), tu.ToTensor()]),\n",
    "    transforms.Compose([tu.RandomDownsample(), tu.ToTensor()])\n",
    "]\n",
    "trsfm = transforms.RandomChoice(transform_options)\n",
    "\n",
    "dataset = tu.BadSensorsDataset(sensors,200, 20, jiggle_offsets=20, transform=trsfm, return_two_transforms=True)\n",
    "\n",
    "dataloader = DataLoader(dataset, 10, shuffle=True)\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, len(sample_batched), len(sample_batched[0]), sample_batched[0][0].size())\n",
    "    s1, s2 = sample_batched\n",
    "    d1 = (s1[0]-s2[0]).abs().sum().numpy()\n",
    "    d2 = (s1[0]-s1[5]).abs().sum().numpy()\n",
    "    if d1 > d2:\n",
    "        print('strange, two augmentations of same sample have larger difference then different samples')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "valid_size = 0.2\n",
    "test_size = 0.1\n",
    "num_workers = 2\n",
    "\n",
    "num_train = len(dataloader)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "train_and_valid_idx, test_idx = indices[split:], indices[:split]\n",
    "num_train = len(train_and_valid_idx)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = train_and_valid_idx[split:], train_and_valid_idx[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampeler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "    sampler=test_sampeler, num_workers=num_workers)\n",
    "\n",
    "# TODO: add train, test, val split (random indexes)\n",
    "# TODO: add code from https://github.com/Spijkervet/SimCLR\n",
    "# TODO: add notebooks: Problem Setup/Description"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.  Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n",
      "0 4 4 torch.Size([200, 3])\n",
      "1 3 3 torch.Size([200, 3])\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    for i_batch, (sk1, sk2) in enumerate(train_loader):\n",
    "        print(i_batch, len(sk1), len(sk2), sk2[0].size())\n",
    "        d1 = (sk1[0]-sk2[0]).abs().sum().numpy()\n",
    "        d2 = (sk1[0]-sk1[2]).abs().sum().numpy()\n",
    "        if d1 > d2:\n",
    "            print('strange, two augmentations of same sample have larger difference then different samples')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}